## 이진 데이터의 전송 안전성

API 서버를 개발하는 중 의문점이 생겼다. 일반적으로 클라이언트와 서버간의 통신에서 데이터를 주고 받을 때는 JSON 형식을 통해 서로 간에 주고 받는다. 하지만 텍스트 데이터만 주고 받는 것이 아니다. 때로는 이미지, 음성과 같은 이진 데이터를 서버가 업로드 받거나 클라이언트가 다운로드 받아야할 경우가 생긴다.

처음에는 이러한 생각이 들었다. 이진 데이터 또한 그저 텍스트 데이터일 뿐인데 JSON의 특정 키에 대한 값으로 보내면 안되나? 하지만 이는 문제를 일으킬 수 있다.

클라이언트와 서버간의 HTTP 통신을 할 때 Content-Type이 `application/json` 혹은 `application/xml`는 텍스트 포맷으로서 기본적으로 UTF-8과 같은 파싱을 거치게 되는데, 이진 데이터는 종종 UTF-8 시퀀스나 제어 바이트(NUL, 0x00)를 포함할 수 있어서 파서에 문제를 일으킨다. 이와 유사한 문제는 이메일(SMTP) 전송 프로토콜에서도 생긴다. SMTP는 7-bit ASCII만 허용하기 때문이다.

참고로 위와 같은 문자열 포맷팅 문제는 네트워크 계층 중 애플리케이션 계층에 의한 것이다. 4계층을 기준으로 애플리케이션, 전송, 인터넷, 네트워크 엑세스 계층 중 애플리케이션을 제외한 계층은 애초에 모든 데이터를 이진 데이터로 다루기 때문에 해당 데이터가 텍스트인지 이미지인지 오디오인지 등은 전혀 신경쓰지않는다. 모든 데이터는 그저 이진 데이터일 뿐이다. 하지만 애플리케이션 계층에서는 해당 이진 데이터를 어떤 형식으로 디코딩하는가에 따라 문제가 발생할 수도 있다.

이를 우회할 수 있는 방법이 Base64로 인코딩하는 것이다. 이진 데이터를 Base64 문자열로 인코딩하면 텍스트 포맷에 대한 파싱에 전혀 문제를 일으키지 않는 문자 조합이 된다. 그래서 HTML 문서에 직접 이진 데이터를 포함해서 전송해야하거나, 이메일 첨부파일 전송 시 사용된다. 그리고 JSON 혹은 XML 데이터 전송 시에도 Base64 인코딩된 문자열이라면, 안정적으로 데이터 전송이 가능하다.

우회할 수 있는 인코딩 방법이 Base64만 존재하는 것은 아니다. `텍스트 경로를 안전히 통과`가 목적이라면 다른 대안이 존재한다.

- Base64URL: +→-, /→_로 바꾼 변형. URL/쿠키에 넣기 수월. 표준은 RFC 4648.
- Base85(Ascii85/Z85): 오버헤드가 ~25%로 더 작음. 다만 지원 범위가 좁고 구현 간 차이가 있어 웹/JSON 생태계에선 덜 보편적.
- Base32: 대소문자 구분 없는 환경에 유리하지만 **오버헤드 ~60%**로 큼. (RFC 4648)
- Hex(Base16): 가장 단순/견고하지만 오버헤드 100%. 디버깅/해시 표기에 적합. (RFC 4648)
- Quoted-Printable: “대부분 텍스트지만 가끔 8-bit 문자가 섞임”에 최적. 순수 바이너리 전체엔 비효율적. 이메일 MIME에서 주로 사용.

그렇다면 이진 데이터를 전송해야할 때는 Base64 인코딩이 필수인가? 그렇지 않다. 사실 이진 데이터 전송 시 인코딩이 필요한 건 텍스트 포맷으로 전송할 때 이거나 프로토콜이 이진 데이터의 형식을 지원하지 않을 때 뿐이다. HTTP를 예로 들면 Content-Type이 `application/json`, `application/xml`인 경우를 제외하고는 별도의 문자 인코딩을 하지 않는다. 그렇기 때문에 굳이 base64 인코딩이 필요없다. 오히려 인코딩을 하기위한 과정과 인코딩으로 인해 커져버린 데이터 크기로 인한 오버헤드만 커질 뿐이다.

애플리케이션 계층에서의 텍스트 인식을 위한 파싱에서 문제를 일으킬 가능성이 있을 뿐이지 다른 저수준에서는 이진 데이터나 텍스트 데이터나 똑같은 데이터로 인식하기 때문에 전달에 문제가 없다.

## 크기가 큰 이진 데이터의 전송

이진 데이터를 전송할 때는 안정성 문제 이외에 추가로 고려해야할 사항이 있다. 그것은 데이터 크기이다. 일반적으로 이미지 혹은 오디오 파일의 경우 MB 단위를 넘는 경우가 존재한다. 이러한 데이터를 한번에 서버에 올렸다가 클라이언트에 전송하는 것은 다양한 부분에서 병목을 일으킬 수 있다.

ChatGPT의 응답은 다음과 같다.

```
좋아요. “스트리밍 없이 큰 파일(이미지, 오디오 등)을 서버에 한 번에 올리고, 그걸 다시 클라이언트에 통째로 내려주는” 패턴에서 병목과 부하 지점을 층별로 짚어볼게요. 한 줄 요약은: **복사·버퍼링·대기 시간**이 눈덩이처럼 불어나는 구조라는 점이에요.

---

경계(엣지)·리버스 프록시 구간

* **요청 바디 버퍼링/임시파일 I/O**
  Nginx 같은 프록시는 기본적으로 클라이언트 요청 바디를 메모리 버퍼에 담다가 크면 디스크 임시파일에 씁니다(`client_body_temp_path`, `proxy_temp_path`). 큰 파일은 디스크 쓰기/읽기 I/O와 공간을 잡아먹고, 느린 클라이언트일수록 프록시가 커넥션을 오래 쥐고 있게 됩니다. ([man.openbsd.org][1], [Nginx][2])

* **응답 버퍼링**
  백엔드에서 오는 큰 응답을 프록시가 메모리와 임시파일에 버퍼링할 수 있어, 메모리 사용량과 디스크 I/O가 증가합니다(`proxy_buffering`). 선택적으로 끌 수 있지만(직접 전달) 트레이드오프가 존재합니다. ([Nginx][3])

* **타임아웃과 에러율 상승**
  대용량 업/다운로드는 `proxy_read_timeout`, `client_body_timeout` 등과 맞물려 413/499/504류 에러로 번지기 쉽습니다. 실전 이슈 레포트가 이를 잘 보여줘요. ([Stack Overflow][4], [docs.rhodecode.com][5])

---

애플리케이션 서버 구간

* **멀티파트 파싱 & 임시 저장 비용**
  Spring Boot 기준으로 업로드는 멀티파트 파서를 거치며, 임계치를 넘으면 디스크로 스필(spill)됩니다. 기본 한도·임계치가 있어 이를 넘으면 예외 또는 과도한 I/O가 발생합니다. (`spring.servlet.multipart.max-file-size`, `max-request-size`, `file-size-threshold`, `location`) ([Home][6], [Baeldung on Kotlin][7])

* **스레드·커넥션 점유**
  비스트리밍(블로킹) 처리면 요청-응답 동안 워커 스레드/커넥션이 붙잡혀 동시성이 확 낮아집니다. 느린 업로더/다운로더가 많을수록 서버 처리량이 줄어요.

* **GC/메모리 압력**
  바이트 배열 복사, 버퍼 누적은 힙과 GC 압력을 올립니다. 프레임워크/라이브러리의 “편한” API가 내부에서 복사를 유발하기 쉬워요.

* **TLS 암복호화 CPU 부담**
  대용량 데이터의 TLS 핸들링은 CPU 사이클을 크게 소모합니다(특히 다운/업 동시 발생 시).

---

스토리지/데이터 경로

* **파일시스템 쓰기 폭주**
  “먼저 서버에 올리고” 방식이면 서버 디스크로 한 번, 다시 내려줄 때 또 한 번 읽습니다. 디스크 대역폭이 공유되면 다른 요청이 굼벵이가 됩니다.

* **DB BLOB 저장의 부작용**
  데이터베이스에 통째로 넣으면 큰 트랜잭션, WAL 폭증, 체크포인트 지연, 백업-복구 시간 증가로 이어집니다. 파일/오브젝트 스토리지로 분리하는 게 흔한 해법인 이유죠.

---

출력(서버→클라이언트) 구간

* **불필요한 복사와 커널/유저 공간 왕복**
  앱이 파일을 유저 공간으로 읽고 다시 소켓으로 쓰면 복사가 2\~3회 이상 발생합니다. 커널의 **zero-copy** 경로(`sendfile` 등)를 안 쓰면 CPU와 메모리 대역폭을 낭비해요. ([LWN.net][8], [IBM Developer][9])

* **대용량 단일 응답의 HOL(Head-of-Line) 지연**
  범위 요청(HTTP **Range**)을 지원하지 않으면 클라이언트 재시도·구간 다운로드가 비효율적이고, 느린 수신자가 소켓을 오래 점유합니다. ([IETF Datatracker][10], [MDN 웹 문서][11])

* **프록시/커널 튜닝 포인트**
  Nginx의 `sendfile`, `directio`, `sendfile_max_chunk` 같은 설정은 큰 파일에서 의미가 큽니다. 잘못 쓰면 오히려 블로킹이 길어져 체감 속도가 나빠질 수 있습니다. ([Nginx][12], [Stack Overflow][13])

---

네트워크·인프라 레벨

* **대역폭 포화 & 큐 적체**
  업링크/다운링크가 포화되면 큐 대기와 지터가 늘고, 다른 API 트래픽까지 느려집니다. 로드밸런서/프록시/서버 NIC 큐가 연쇄적으로 적체될 수 있어요.

* **캐시/에지 미사용 비용**
  CDN/에지 캐시 없이 원서버가 매번 전체 파일을 서빙하면, 원본 I/O와 네트워크가 항상 ‘핫’해집니다. Range GET을 이해하는 CDN(예: CloudFront)은 부분 전송·재개에 유리합니다. ([AWS 문서][14])

* **로그/모니터링 오버헤드**
  대용량 전송이 많으면 접근 로그·메트릭 수집 자체도 I/O와 CPU를 먹습니다.

---

## “통째로 올리고 통째로 내리는” 구조의 전형적 병목 요약

1. **프록시·앱·OS 전 구간의 중복 버퍼링/복사** → 메모리·CPU·디스크 I/O 폭증
2. **느린 클라이언트가 커넥션·스레드 장시간 점유** → 처리량 하락
3. **디스크를 두 번(쓰기+읽기)** → I/O 병목, 스토리지 공간 압박
4. **Range/zero-copy 미활용** → 회복력·효율 저하
```

내용이 굉장히 긴데 어쨋든 다양한 부분에서 부하를 받게된다는 내용이다. 그렇다면 해당 문제를 어떻게 해결해야할까?

일단 API 서버 관점에서만 보자. 만약 파일이 서버 컴퓨터에 저장되어 있고, 이를 클라이언트에 전송해야한다면, 스트리밍 응답을 고려한다. 디스크에서 클라이언트에 응답하는 파이프라이닝을 하여, 서버에 한꺼번에 모든 데이터가 올라가지 않기 때문에 메모리 부하를 크게 받지 않으며, 부수적인 문제도 완화된다.

## 텍스트가 아닌 데이터를 네트워크 상에서 전송하는 현실적인 방법

- 멀티파트 전송(multipart/form-data)은 텍스트와 파일(이진) 데이터를 분리하여 전송이 가능하다.
- 해당 파일 데이터를 전송하기위한 적절한 형식을 사용한다. (image/png, image/jpeg, audio/mpeg, ...)
- JSON 혹은 XML 과 같은 문자열 데이터 형식을 꼭 사용해야한다면, Base64 인코딩으로 전송한다.