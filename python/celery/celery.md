## Celery는?

- 간단함: 사용하고 유지보수하기 쉬우며, 별도의 구성 파일 작성을 요구하지 않는다.
- 고가용성: 작업자와 클라이언트는 연결 손실 또는 실패 시 자동으로 재시작하며, 일부 브로커는 주/주, 주/부 복제 방식을 통해 고가용성을 지원한다.
- 빠름: 단일 Celery 프로세스는 분당 수 백만개의 작업을 처리할 수 있으며, 최적화된 설정을 사용 시 서브 밀리초 수준의 왕복 지연 시간을 달성할 수 있다.
- 유연함: 거의 모든 부분은 확장하거나 독립적으로 사용할 수 있다. 사용자 정의 풀, 직렬화, 압축 방식, 로깅, 스케줄러 등 다양한 기능 포함

## 지원 사항

- 브로커
  - RabbitMQ, Redis
  - Amazon SQS
- 동시성
  - prefork(multiprocessing)
  - Eventlet, gevent
  - thread(multithread)
  - solo(single thread)
- 결과 저장소
  - AMQP, Redis
  - Memcached
  - SQLAlchemy, Django ORM
  - Apache Cassandra, Elasticsearch, Riak
  - MongoDB, CouchDB, Couchbase, ArangoDB
  - Amazon DynamoDB, Amazon S3
  - Microsoft Azure Block Blob, Microsoft Azure Cosmos DB
  - Google Cloud Storage
  - File system
- 직렬화
  - pickle, json, yaml, msgpack.
  - zlib, bzip2 compression.
  - Cryptographic message signing.

## 기능

- 모니터링
    작업자에서 모니터링 이벤트의 스트림이 생성되며, 이 스트림은 내장 및 외부 도구에 의해 사용되어 클러스터가 현재 수행 중인 작업을 실시간으로 알림
- 스케줄링
    작업 실행 시간을 초 단위 또는 날짜/시간 형식으로 지정할 수 있으며, 간단한 간격에 기반한 반복 이벤트를 위해 주기적 작업을 사용하거나 분, 시, 주간, 월간, 연간 반복을 지원하는 crontab 표현식을 사용할 수 있다.
- 워크 플로우
    간단한 작업 흐름과 복잡한 작업 흐름은 "canvas"라고 부르는 강력한 기본 요소 집합을 사용하여 구성할 수 있다. 이 기본 요소에는 그룹화, 연결, 분할 등이 포함된다.
- 자원 유출 방지
    `--max-tasks-per-child` 옵션은 메모리나 파일 디스크립터 등 사용자가 통제할 수 없는 자원을 유출하는 사용자 작업에 사용
- 시간 및 속도 제한
    초/분/시간당 실행할 수 있는 작업 수 또는 작업이 실행될 수 있는 최대 시간을 제어할 수 있으며, 이는 기본 설정으로 설정되거나 특정 작업자 또는 각 작업 유형별로 개별적으로 설정할 수 있다.
- 사용자 구성요소
    각 작업자 구성 요소는 사용자 정의가 가능하며, 사용자는 추가 구성 요소를 정의할 수 있다. 작업자는 `bootsteps`를 사용하여 구성된다. 작업자 내부 구조를 세밀하게 제어할 수 있는 의존성 그래프이다.

## Celery 구조 파헤치기

Celery 프로젝트는 동기식 웹 프레임워크에 백그라운드 작업을 실행하기 위해 많이 사용되는 Python 라이브러리이다.

Celery는 방대한 양의 메시지를 처리하기 위한 단순하고 유연하며 신뢰할 수 있는 분산 시스템으로, 이러한 시스템을 유지 관리하기 위해 필요한 도구를 제공한다. 실시간 처리에 초점을 맞춘 작업 큐이지만, 작업 스케쥴링도 지원한다.(Celery Beat)

### 고수준 아키텍처

Celery는 몇 가지 메인 컴포넌트로 이루어져 있다.

![celery-overview](./celery-overview.png)

- task, 나의 애플리케이션 코드이다. 내가 정의한 작업을 수행하는 컴포넌트이다.
- broker
- 하나 혹은 둘 이상의 worker
- backend

Celery를 사용하기 위해서는 다음의 과정을 거쳐야한다.

1. Celery 애플리케이션을 인스턴스화 하고(구성 설정) 하나 이상의 작업 함수를 정의한다.
2. 브로커를 실행한다.
3. 하나 이상의 워커를 실행한다.
4. (필요에 따라) 백엔드를 실행한다.

![celery-components](./celery-components.png)

#### Broker

메시지 브로커는 작업 요청을 수신하고 작업자가 처리할 준비가 될 때까지 이를 대기열에 저장하는 상용 소프트웨어이다. 일반적인 옵션으로는 RabbitMQ나 Redis가 있지만, 클라우드 제공업체에서 맞춤형 브로커를 제공받을 수 있다.

브로커는 교환기와 하나 이상의 큐와 같은 하위 구성 요소를 포함할 수 있다. (참고: Celery는 AMQP 용어를 주로 사용하며, 다른 브로커에 존재하지 않는 기능을 모방하는 경우도 있다.)

브로커 구성은 이 문서의 범위를 넘어간다.

#### Worker

Celery 작업자는 브로커에서 대기 중인 작업을 가져와서 해당 작업에 정의된 코드를 실행 한다. 작업자는 선택적으로 결과 백엔드를 통해 값을 반환할 수 있다.

Celery 워커는 브로커에서 작업을 가져오는 "컨슈머"를 가지고 있다. 기본적으로 한번에 여러 개의 작업을 요청하며, 이는 "prepatch multiplier x concurrency"와 동일하다. (프리패치 곱수가 5이고 동시 실행 수가 4하면, 브로커에서 최대 20개의 대기 중인 작업을 가져오려고 시도한다.) 사져온 작업은 메모리 내 버퍼에 저장된다. 작업 풀은 각 작업을 전략을 통해 실행한다. 일반적인 Celery 작업의 경우 작업 풀은 기본적으로 소비자 버퍼에서 작업을 실행한다.

워커는 미래에 실행될 작업을 스케줄링하는 기능(메모리 내 큐잉)도 처리한다. "prefork" 풀을 사용할 경우 소비자 및 작업 풀은 별도의 프로세스로 실행되며, "gevent"/"eventlet" 풀은 코루틴을 사용하고, "threads" 풀은 스레드를 사용한다. 테스트에 유용한 "solo" 풀도 있으며, 이 경우 모든 것이 동일한 프로세스 내에서 실행된다. (단일 작업이 한 번에 실행되며, 소비자가 추가 작업을 가져오는 것을 차단한다.)

#### Backend

백엔드는 작업 결과물을 저장하기 위해 사용되는 또 다른 상용 소프트웨어이다. 이 소프트웨어는 키-값 저장소를 제공하며, 일반적으로 Redis가 사용되지만, 결과물의 내구성과 크기에 따라 다양한 옵션이 존재한다. 결과물 백엔드는 애플리케이션 코드레 반환되는 AsyncResult 객체를 통해 쿼리할 수 있다.

### Dataflow

구성 요소들은 최소한 여러 가지 다른 프로세스(클라이언트, 브로커, 워커, 워커 풀, 백엔드)를 포함하며, 이 프로세스들은 서로 다른 컴퓨터에 존재할 수도 있다.

가장 중요한 점은 각 프로세스 경계에서 많은 직렬화 작업이 발생한다는 것이다.

![celery-dataflow](./celery-dataflow.png)

### 요청 직렬화

클라이언트가 작업을 실행하도록 요청할 때 해당 정보는 브로커가 이해할 수 있는 형식으로 전달되어야한다. 필요한 데이터는 다음과 같은 항목이 포함된다.

- 작업 식별자
- 인수
- 요청 ID
- 라우팅 정보
- 기타 다양한 메타데이터

정확히 어떤 정보가 포함되는지는 메시지 프로토콜에 의해 정의된다. (Celery는 두 가지 프로토콜을 지원하지만, 두 프로토콜은 상당히 유사하다.)

대부분의 메타데이터는 헤더에 배치되며, 작업 인수는 어떤 Python 클래스든 될 수 있으며, 본문에 직렬화되어야 한다. Celery는 많은 직렬화를 지원하며 기본적으로 JSON을 사용한다. (pickle, YAML, msgpack 및 사용자 스키마도 사용할 수 있다.)

직렬화 후 Celery는 추가 보안을 위해 메시지를 압축하거나 서명하는 것도 지원한다.

다음은 RabbitMQ의 관리 인터페이스에서 전송된 작업 요청의 세부 정보를 포함하는 AMQP 메시지의 예시이다.

![rabbitmq-task-message](./rabbitmq-task-message.png)

작업자가 브로커에서 작업을 가져올 때 해당 작업을 Request로 역직렬화하고 실행한다. "prefork" 작업자 풀의 경우 Request는 작업자 풀로 전달될 대 pickle을 사용하여 다시 직렬화 한다.

작업자 풀을 요청을 디피클링한 후 작업 코드를 로드하고 요청된 인수로 작업을 실행한다. 이제 작업 코드가 실행된다. 주의할 점은 작업 코드 자체가 직렬화된 요청에 포함되지 않으며, 작업자가 별도로 로드한다는 점이다.

### 결과 직렬화

작업이 값을 반환하면 해당 값은 원본 클라이언트가 이를 찾을 수 있도록 충분한 정보와 함께 결과 백엔드에 저장된다.

- 결과 ID
- 결과 값
- 기타 메타 데이터

작업과 마찬가지로 이 정보는 결과 백엔드에 저장되기 전에 직렬화되어야 하며(헤더와 본문에 분할되어 저장) Celery는 이 직렬화를 사용자 정의할 수 있는 구성 옵션을 제공한다.

결과 세부 정보를 포함하는 AMQP 메시지의 예시는 다음과 같다.

![rabbitmq-result-message](./rabbitmq-result-message.png)


## 참조

https://patrick.cloke.us/posts/2023/09/15/celery-architecture-breakdown/